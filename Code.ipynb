{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XSzqyu3iElw2",
        "zJ6uFKtfHP2P"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om0-00owEHou",
        "outputId": "538be372-0cf5-4def-f5ca-804fc0a6a57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 38.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 54.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 163 kB 73.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tokenization"
      ],
      "metadata": {
        "id": "HFA2mqErO_ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XfUP3yfdL2t",
        "outputId": "b731415d-4842-43d2-cd2d-83822d931ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 34.2 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 163 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 184 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 215 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 225 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 235 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 245 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 256 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 276 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 286 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 296 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 307 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 317 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 327 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 337 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 348 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 358 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 368 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 378 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 389 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 399 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 409 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 419 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 430 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 440 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 450 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 460 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 471 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 481 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 491 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 501 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 512 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 522 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 532 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 542 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 552 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 563 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 573 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 583 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 593 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 604 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 614 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 624 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 634 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 645 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 655 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 665 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 675 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 686 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 696 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 706 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 716 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 727 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 737 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 747 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 757 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 768 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 778 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 788 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 798 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 808 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 819 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 829 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 839 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 849 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 860 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 870 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 880 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 890 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 901 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 911 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 921 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 931 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 942 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 952 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 962 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 972 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 983 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 993 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.0 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.3 MB 29.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 29.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --output-document='./token_1.py' https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/tools/tokenization.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taDNmmDlQJPV",
        "outputId": "9cb316c7-aec0-4688-cbee-2f62e59ae15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-05 15:19:07--  https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/tools/tokenization.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16591 (16K) [text/plain]\n",
            "Saving to: ‘./token_1.py’\n",
            "\n",
            "\r./token_1.py          0%[                    ]       0  --.-KB/s               \r./token_1.py        100%[===================>]  16.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-05 15:19:07 (100 MB/s) - ‘./token_1.py’ saved [16591/16591]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "import token_1 as  tokenization"
      ],
      "metadata": {
        "id": "x6svO8ildOsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "7wHlG_STEBjk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BKE9pXZD7QE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "import transformers as ppb\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tokenization\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.utils import np_utils\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "ZXOTjK9ZEYnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone 'https://github.com/ayaanzhaque/SDCNL.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPbHJRXsD_vU",
        "outputId": "c8e61162-3308-4547-eaf5-93045893ea6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SDCNL'...\n",
            "remote: Enumerating objects: 155, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
            "remote: Total 155 (delta 59), reused 97 (delta 24), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (155/155), 5.65 MiB | 34.63 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls './SDCNL/data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf27teVmEO_a",
        "outputId": "50fa4a5e-1474-43d1-d832-0436a661f9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "combined-set.csv  testing-set.csv  training-set.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/SDCNL/data/training-set.csv', index_col=0).sort_index()[['selftext', 'is_suicide']].dropna()\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LF5vERboEPo9",
        "outputId": "a030eb28-6257-4967-d511-c5fad77cdac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            selftext  is_suicide\n",
              "0  I've been feeling really depressed and lonely ...           0\n",
              "1  I literally broke down crying and asked to go ...           0\n",
              "2  Any kind soul want to give a depressed person ...           0\n",
              "3       literally though. have i done anything wrong           0\n",
              "4  why does it hurt so much? Why can’t I be happy...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aed088fe-9b70-47e4-9258-0c01aaec8417\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>selftext</th>\n",
              "      <th>is_suicide</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I've been feeling really depressed and lonely ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I literally broke down crying and asked to go ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Any kind soul want to give a depressed person ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>literally though. have i done anything wrong</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>why does it hurt so much? Why can’t I be happy...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aed088fe-9b70-47e4-9258-0c01aaec8417')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aed088fe-9b70-47e4-9258-0c01aaec8417 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aed088fe-9b70-47e4-9258-0c01aaec8417');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/SDCNL/data/testing-set.csv', index_col=0).sort_index()[['selftext', 'is_suicide']].dropna()\n",
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "E6h3pFO-ERGk",
        "outputId": "c13078e3-8521-44cb-9864-3b293db98eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             selftext  is_suicide\n",
              "23  Any song which you like which makes you feel g...           0\n",
              "29  I find it difficult right now to believe a per...           0\n",
              "30  so i’ve had a few run ins with counselors in t...           0\n",
              "32  Let's have some fucking fun, do stupid shit, l...           0\n",
              "44  I feel the only thing that makes me even remot...           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-262297ed-62a8-4f77-8882-577afc42c9e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>selftext</th>\n",
              "      <th>is_suicide</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Any song which you like which makes you feel g...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>I find it difficult right now to believe a per...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>so i’ve had a few run ins with counselors in t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Let's have some fucking fun, do stupid shit, l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>I feel the only thing that makes me even remot...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-262297ed-62a8-4f77-8882-577afc42c9e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-262297ed-62a8-4f77-8882-577afc42c9e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-262297ed-62a8-4f77-8882-577afc42c9e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = preprocessing.LabelEncoder()\n",
        "y_train = label.fit_transform(train['is_suicide'])\n",
        "y_train = to_categorical(y_train)\n",
        "print(y_train[:3])\n",
        "print(y_train[-2:])\n",
        "\n",
        "\n",
        "label = preprocessing.LabelEncoder()\n",
        "y_test = label.fit_transform(test['is_suicide'])\n",
        "y_test = to_categorical(y_test)\n",
        "print(y_test[:3])\n",
        "print(y_test[-2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK_9DGjacYiE",
        "outputId": "045a2c0d-9a91-4fea-9193-7ddab64463d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "[[0. 1.]\n",
            " [0. 1.]]\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "[[0. 1.]\n",
            " [0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train), len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wXzW6ziP-fg",
        "outputId": "100ad4ab-a22c-4224-86b4-af54ea6f2010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1516 379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Embeddings"
      ],
      "metadata": {
        "id": "XSzqyu3iElw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGtkg6BdEiyF",
        "outputId": "ec0b2548-a6bf-4dd9-b08f-9a9a1a9c1271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getFeatures(batch_1):\n",
        "\n",
        "    tokenized = batch_1[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512)))\n",
        "\n",
        "    max_len = 0\n",
        "    for i in tokenized.values:\n",
        "        if len(i) > max_len:\n",
        "            max_len = len(i)\n",
        "\n",
        "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "\n",
        "\n",
        "    attention_mask = np.where(padded != 0, 1, 0)\n",
        "    attention_mask.shape\n",
        "\n",
        "\n",
        "    input_ids = torch.tensor(padded)\n",
        "    attention_mask = torch.tensor(attention_mask)\n",
        "    print('before with')\n",
        "    with torch.no_grad():\n",
        "        print('in with')\n",
        "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "    print('after with\\n')\n",
        "\n",
        "    features = last_hidden_states[0][:,-1,:].numpy() # use this line if you want the 2D BERT features\n",
        "    # features = last_hidden_states[0].numpy() # use this line if you want the 3D BERT features\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "0BC2QnEDEoTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = data[['selftext', 'is_suicide']].dropna()\n",
        "df = df.rename(columns={'selftext': 0, 'is_suicide': 1})\n",
        "t0 = time.time()\n",
        "ber = []\n",
        "k = 200\n",
        "for i in range(0, len(df), k):\n",
        "    bert_features = getFeatures(df[i:i+k])\n",
        "    ber.append(bert_features)\n",
        "print(\"time taken:\", str(time.time()-t0))\n",
        "\n",
        "bert_features = np.zeros((len(df), ber[0].shape[1]))\n",
        "\n",
        "np.save('content/bert_features.npy', bert_features)"
      ],
      "metadata": {
        "id": "qMVZsTggEp0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "print('Upload numpy:')\n",
        "files.upload()\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "XgjqkFFJE1SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_features = np.load('/content/bert_features (1).npy')"
      ],
      "metadata": {
        "id": "RO0LqPwAErlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Embeddings - 2"
      ],
      "metadata": {
        "id": "lgp78-ZoOqGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2', trainable=True)"
      ],
      "metadata": {
        "id": "w6SJtNJVO3P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "\n",
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "\n",
        "    for text in tqdm(texts):\n",
        "        text = tokenizer.tokenize(text)\n",
        "\n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len-len(input_sequence)\n",
        "\n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "\n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "\n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "metadata": {
        "id": "QVHjhmIDNp9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Classification"
      ],
      "metadata": {
        "id": "zJ6uFKtfHP2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "id": "hMDXwERtEw1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U \"tensorflow-text==2.8.*\""
      ],
      "metadata": {
        "id": "0C1nWvJLHHQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tf-models-official==2.7.0"
      ],
      "metadata": {
        "id": "1Q6Rm1ktHIhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer"
      ],
      "metadata": {
        "id": "lMcfWk7eHJpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ],
      "metadata": {
        "id": "xwL2KaQtHNfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(bert_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "wLKyFD1iJK4l",
        "outputId": "3d850624-3ffe-4b20-a515-036bbe1a19f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0    -0.005627  0.197340  0.255266 -0.202157 -0.127188 -0.023924  0.095443   \n",
              "1     0.041702  0.033158  0.391555  0.083243 -0.106265  0.007643  0.104453   \n",
              "2     0.124002 -0.305653  0.690137  0.400152  0.047422 -0.221045  0.383370   \n",
              "3    -0.067380 -0.306545 -0.084634 -0.082586  0.044260 -0.390153  0.344334   \n",
              "4    -0.093186 -0.096373  0.538901  0.187397 -0.235153  0.051056  0.359623   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1511  0.066812  0.207072  0.342999 -0.084594 -0.192420 -0.182517  0.308774   \n",
              "1512  0.338397  0.066267  0.316055 -0.145459 -0.310907  0.011319  0.218389   \n",
              "1513  0.168676  0.177153  0.279387 -0.055107  0.007915  0.008404  0.169118   \n",
              "1514  0.325733  0.150278  0.726998 -0.022928 -0.276218 -0.241435  0.224024   \n",
              "1515 -0.082677 -0.196004  0.324467  0.165619 -0.275965 -0.030240  0.246603   \n",
              "\n",
              "           7         8         9    ...       758       759       760  \\\n",
              "0    -0.155857 -0.009765  0.199888  ...  0.135710 -0.029776 -0.087515   \n",
              "1     0.318385  0.099034 -0.282493  ...  0.254370 -0.175711  0.252428   \n",
              "2     0.536844  0.036519 -0.449553  ...  0.302180 -0.112828 -0.300580   \n",
              "3     0.257576 -0.184936 -0.321719  ...  0.708768 -0.302354  0.195586   \n",
              "4     0.207580  0.168766 -0.277475  ...  0.216742 -0.032568  0.162220   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1511  0.253753  0.262220 -0.047239  ...  0.689600 -0.146555 -0.162750   \n",
              "1512  0.154832 -0.150733 -0.346169  ...  0.406083  0.084853  0.243279   \n",
              "1513 -0.186396  0.078828 -0.274420  ... -0.139662  0.229705  0.144622   \n",
              "1514 -0.056770  0.193431 -0.226460  ...  0.520330 -0.191626  0.108536   \n",
              "1515  0.421476  0.211577 -0.090123  ...  0.696644 -0.164771 -0.043184   \n",
              "\n",
              "           761       762       763       764       765       766       767  \n",
              "0    -0.076553  0.333864 -0.538846 -0.308195 -0.292609  0.220776 -0.540935  \n",
              "1    -0.223801  0.207414 -0.140773 -0.297795  0.228355 -0.272897 -0.330350  \n",
              "2     0.049018 -0.011509 -0.183170 -0.481234  0.440657  0.101002 -0.424336  \n",
              "3    -0.633363  0.031786 -0.063108 -0.263744  0.019093  0.128779 -0.033784  \n",
              "4    -0.206016  0.092918 -0.099344 -0.311719 -0.088092 -0.173600 -0.261069  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "1511 -0.180754  0.272482 -0.121546 -0.254629  0.241042 -0.079238 -0.196741  \n",
              "1512 -0.075377  0.503267 -0.057837 -0.470347  0.091725 -0.069153 -0.426897  \n",
              "1513  0.011850  0.184867 -0.164814 -0.549298  0.110181  0.140944 -0.200547  \n",
              "1514  0.006055  0.023296  0.209091 -0.139315  0.196952  0.012726  0.363018  \n",
              "1515 -0.421873  0.023441 -0.089947 -0.364911  0.387632 -0.099321 -0.222992  \n",
              "\n",
              "[1516 rows x 768 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79fd6c55-99fc-4c2b-b6f8-335c71d85950\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.005627</td>\n",
              "      <td>0.197340</td>\n",
              "      <td>0.255266</td>\n",
              "      <td>-0.202157</td>\n",
              "      <td>-0.127188</td>\n",
              "      <td>-0.023924</td>\n",
              "      <td>0.095443</td>\n",
              "      <td>-0.155857</td>\n",
              "      <td>-0.009765</td>\n",
              "      <td>0.199888</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135710</td>\n",
              "      <td>-0.029776</td>\n",
              "      <td>-0.087515</td>\n",
              "      <td>-0.076553</td>\n",
              "      <td>0.333864</td>\n",
              "      <td>-0.538846</td>\n",
              "      <td>-0.308195</td>\n",
              "      <td>-0.292609</td>\n",
              "      <td>0.220776</td>\n",
              "      <td>-0.540935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.041702</td>\n",
              "      <td>0.033158</td>\n",
              "      <td>0.391555</td>\n",
              "      <td>0.083243</td>\n",
              "      <td>-0.106265</td>\n",
              "      <td>0.007643</td>\n",
              "      <td>0.104453</td>\n",
              "      <td>0.318385</td>\n",
              "      <td>0.099034</td>\n",
              "      <td>-0.282493</td>\n",
              "      <td>...</td>\n",
              "      <td>0.254370</td>\n",
              "      <td>-0.175711</td>\n",
              "      <td>0.252428</td>\n",
              "      <td>-0.223801</td>\n",
              "      <td>0.207414</td>\n",
              "      <td>-0.140773</td>\n",
              "      <td>-0.297795</td>\n",
              "      <td>0.228355</td>\n",
              "      <td>-0.272897</td>\n",
              "      <td>-0.330350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.124002</td>\n",
              "      <td>-0.305653</td>\n",
              "      <td>0.690137</td>\n",
              "      <td>0.400152</td>\n",
              "      <td>0.047422</td>\n",
              "      <td>-0.221045</td>\n",
              "      <td>0.383370</td>\n",
              "      <td>0.536844</td>\n",
              "      <td>0.036519</td>\n",
              "      <td>-0.449553</td>\n",
              "      <td>...</td>\n",
              "      <td>0.302180</td>\n",
              "      <td>-0.112828</td>\n",
              "      <td>-0.300580</td>\n",
              "      <td>0.049018</td>\n",
              "      <td>-0.011509</td>\n",
              "      <td>-0.183170</td>\n",
              "      <td>-0.481234</td>\n",
              "      <td>0.440657</td>\n",
              "      <td>0.101002</td>\n",
              "      <td>-0.424336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.067380</td>\n",
              "      <td>-0.306545</td>\n",
              "      <td>-0.084634</td>\n",
              "      <td>-0.082586</td>\n",
              "      <td>0.044260</td>\n",
              "      <td>-0.390153</td>\n",
              "      <td>0.344334</td>\n",
              "      <td>0.257576</td>\n",
              "      <td>-0.184936</td>\n",
              "      <td>-0.321719</td>\n",
              "      <td>...</td>\n",
              "      <td>0.708768</td>\n",
              "      <td>-0.302354</td>\n",
              "      <td>0.195586</td>\n",
              "      <td>-0.633363</td>\n",
              "      <td>0.031786</td>\n",
              "      <td>-0.063108</td>\n",
              "      <td>-0.263744</td>\n",
              "      <td>0.019093</td>\n",
              "      <td>0.128779</td>\n",
              "      <td>-0.033784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.093186</td>\n",
              "      <td>-0.096373</td>\n",
              "      <td>0.538901</td>\n",
              "      <td>0.187397</td>\n",
              "      <td>-0.235153</td>\n",
              "      <td>0.051056</td>\n",
              "      <td>0.359623</td>\n",
              "      <td>0.207580</td>\n",
              "      <td>0.168766</td>\n",
              "      <td>-0.277475</td>\n",
              "      <td>...</td>\n",
              "      <td>0.216742</td>\n",
              "      <td>-0.032568</td>\n",
              "      <td>0.162220</td>\n",
              "      <td>-0.206016</td>\n",
              "      <td>0.092918</td>\n",
              "      <td>-0.099344</td>\n",
              "      <td>-0.311719</td>\n",
              "      <td>-0.088092</td>\n",
              "      <td>-0.173600</td>\n",
              "      <td>-0.261069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>0.066812</td>\n",
              "      <td>0.207072</td>\n",
              "      <td>0.342999</td>\n",
              "      <td>-0.084594</td>\n",
              "      <td>-0.192420</td>\n",
              "      <td>-0.182517</td>\n",
              "      <td>0.308774</td>\n",
              "      <td>0.253753</td>\n",
              "      <td>0.262220</td>\n",
              "      <td>-0.047239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.689600</td>\n",
              "      <td>-0.146555</td>\n",
              "      <td>-0.162750</td>\n",
              "      <td>-0.180754</td>\n",
              "      <td>0.272482</td>\n",
              "      <td>-0.121546</td>\n",
              "      <td>-0.254629</td>\n",
              "      <td>0.241042</td>\n",
              "      <td>-0.079238</td>\n",
              "      <td>-0.196741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>0.338397</td>\n",
              "      <td>0.066267</td>\n",
              "      <td>0.316055</td>\n",
              "      <td>-0.145459</td>\n",
              "      <td>-0.310907</td>\n",
              "      <td>0.011319</td>\n",
              "      <td>0.218389</td>\n",
              "      <td>0.154832</td>\n",
              "      <td>-0.150733</td>\n",
              "      <td>-0.346169</td>\n",
              "      <td>...</td>\n",
              "      <td>0.406083</td>\n",
              "      <td>0.084853</td>\n",
              "      <td>0.243279</td>\n",
              "      <td>-0.075377</td>\n",
              "      <td>0.503267</td>\n",
              "      <td>-0.057837</td>\n",
              "      <td>-0.470347</td>\n",
              "      <td>0.091725</td>\n",
              "      <td>-0.069153</td>\n",
              "      <td>-0.426897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>0.168676</td>\n",
              "      <td>0.177153</td>\n",
              "      <td>0.279387</td>\n",
              "      <td>-0.055107</td>\n",
              "      <td>0.007915</td>\n",
              "      <td>0.008404</td>\n",
              "      <td>0.169118</td>\n",
              "      <td>-0.186396</td>\n",
              "      <td>0.078828</td>\n",
              "      <td>-0.274420</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.139662</td>\n",
              "      <td>0.229705</td>\n",
              "      <td>0.144622</td>\n",
              "      <td>0.011850</td>\n",
              "      <td>0.184867</td>\n",
              "      <td>-0.164814</td>\n",
              "      <td>-0.549298</td>\n",
              "      <td>0.110181</td>\n",
              "      <td>0.140944</td>\n",
              "      <td>-0.200547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>0.325733</td>\n",
              "      <td>0.150278</td>\n",
              "      <td>0.726998</td>\n",
              "      <td>-0.022928</td>\n",
              "      <td>-0.276218</td>\n",
              "      <td>-0.241435</td>\n",
              "      <td>0.224024</td>\n",
              "      <td>-0.056770</td>\n",
              "      <td>0.193431</td>\n",
              "      <td>-0.226460</td>\n",
              "      <td>...</td>\n",
              "      <td>0.520330</td>\n",
              "      <td>-0.191626</td>\n",
              "      <td>0.108536</td>\n",
              "      <td>0.006055</td>\n",
              "      <td>0.023296</td>\n",
              "      <td>0.209091</td>\n",
              "      <td>-0.139315</td>\n",
              "      <td>0.196952</td>\n",
              "      <td>0.012726</td>\n",
              "      <td>0.363018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>-0.082677</td>\n",
              "      <td>-0.196004</td>\n",
              "      <td>0.324467</td>\n",
              "      <td>0.165619</td>\n",
              "      <td>-0.275965</td>\n",
              "      <td>-0.030240</td>\n",
              "      <td>0.246603</td>\n",
              "      <td>0.421476</td>\n",
              "      <td>0.211577</td>\n",
              "      <td>-0.090123</td>\n",
              "      <td>...</td>\n",
              "      <td>0.696644</td>\n",
              "      <td>-0.164771</td>\n",
              "      <td>-0.043184</td>\n",
              "      <td>-0.421873</td>\n",
              "      <td>0.023441</td>\n",
              "      <td>-0.089947</td>\n",
              "      <td>-0.364911</td>\n",
              "      <td>0.387632</td>\n",
              "      <td>-0.099321</td>\n",
              "      <td>-0.222992</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1516 rows × 768 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79fd6c55-99fc-4c2b-b6f8-335c71d85950')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79fd6c55-99fc-4c2b-b6f8-335c71d85950 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79fd6c55-99fc-4c2b-b6f8-335c71d85950');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3PvMbcjLzDJ",
        "outputId": "2cc4124d-a78c-452c-fb7e-a084baf98443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(bert_features,df['is_suicide'].to_numpy(), stratify=df['is_suicide'].to_numpy(), test_size = 0.25)"
      ],
      "metadata": {
        "id": "roteHEdgI69Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT1U8qD7Ja2Y",
        "outputId": "eef9ce01-9534-4ac7-f8ff-b2158ae33b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1137, 768)\n",
            "(379, 768)\n",
            "(1137,)\n",
            "(379,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_embedded_input = tf.keras.layers.Input(shape=(), dtype=tf.int32)\n",
        "# preprocessed_text = bert_preprocess(text_input)\n",
        "# outputs = bert_encoder(preprocessed_text)\n",
        "# # Neural network layers\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(text_embedded_input)\n",
        "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "# Use inputs and outputs to construct a final model\n",
        "model = tf.keras.Model(inputs=[text_embedded_input], outputs = [l])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "2XcNj5ILMbXn",
        "outputId": "e6e715e1-c04e-400d-c75b-6b7cf9cf25fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-61933c205862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# # Neural network layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dropout\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embedded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Use inputs and outputs to construct a final model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_embedded_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[1;32m    229\u001b[0m                          \u001b[0;34m'is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                          \u001b[0;34mf'expected min_ndim={spec.min_ndim}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"output\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Classification - 2"
      ],
      "metadata": {
        "id": "vsTqQv1gPYKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(bert_layer, max_len):\n",
        "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "\n",
        "    lay = tf.keras.layers.Dense(512, activation='relu')(clf_output)\n",
        "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
        "    lay = tf.keras.layers.Dense(128, activation='relu')(lay)\n",
        "    lay = tf.keras.layers.Dense(64, activation='relu')(lay)\n",
        "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
        "    lay = tf.keras.layers.Dense(32, activation='relu')(lay)\n",
        "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
        "    out = tf.keras.layers.Dense(len(y_train[0]), activation='softmax')(lay)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy', 'mae'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "G71joaSbOfUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 512\n",
        "train_input = bert_encode(train.selftext.values, tokenizer, max_len=max_len)\n",
        "test_input = bert_encode(test.selftext.values, tokenizer, max_len=max_len)\n",
        "train_labels = y_train\n",
        "test_labels = y_test"
      ],
      "metadata": {
        "id": "Bb08_9zwPejr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2207827c-2b4e-4b16-dc0c-2cdbf6182a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1516/1516 [00:05<00:00, 292.83it/s]\n",
            "100%|██████████| 379/379 [00:00<00:00, 429.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(bert_layer, max_len=max_len)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ok4eoo_0MvLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9edb054-3409-48e8-f5a0-87e23cb35262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer)    [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)     [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
            "                                 (None, 512, 768)]                'input_mask[0][0]',             \n",
            "                                                                  'segment_ids[0][0]']            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['keras_layer_1[0][1]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128)          65664       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           8256        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 64)           0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 32)           2080        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 32)           0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 2)            66          ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,952,035\n",
            "Trainable params: 109,952,034\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)\n",
        "\n",
        "train_sh = model.fit(\n",
        "    train_input, train_labels,\n",
        "    validation_split=0.25,\n",
        "    epochs=50,\n",
        "    callbacks=[checkpoint, earlystopping],\n",
        "    batch_size=8,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mdhNeM_Q9v5",
        "outputId": "b2136431-0169-4d1b-82fb-e0af9bfd2dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "143/143 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.6464 - mae: 0.4227\n",
            "Epoch 1: val_accuracy improved from -inf to 0.05805, saving model to model.h5\n",
            "143/143 [==============================] - 164s 1s/step - loss: 0.6482 - accuracy: 0.6464 - mae: 0.4227 - val_loss: 1.2725 - val_accuracy: 0.0580 - val_mae: 0.8250\n",
            "Epoch 2/50\n",
            "143/143 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.6974 - mae: 0.3561\n",
            "Epoch 2: val_accuracy improved from 0.05805 to 0.47757, saving model to model.h5\n",
            "143/143 [==============================] - 165s 1s/step - loss: 0.5890 - accuracy: 0.6974 - mae: 0.3561 - val_loss: 0.8911 - val_accuracy: 0.4776 - val_mae: 0.5780\n",
            "Epoch 3/50\n",
            "143/143 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.7748 - mae: 0.2749\n",
            "Epoch 3: val_accuracy improved from 0.47757 to 0.81530, saving model to model.h5\n",
            "143/143 [==============================] - 165s 1s/step - loss: 0.4889 - accuracy: 0.7748 - mae: 0.2749 - val_loss: 0.5239 - val_accuracy: 0.8153 - val_mae: 0.2862\n",
            "Epoch 4/50\n",
            "143/143 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8549 - mae: 0.1866\n",
            "Epoch 4: val_accuracy did not improve from 0.81530\n",
            "143/143 [==============================] - 159s 1s/step - loss: 0.3877 - accuracy: 0.8549 - mae: 0.1866 - val_loss: 1.2021 - val_accuracy: 0.5409 - val_mae: 0.4874\n",
            "Epoch 5/50\n",
            "143/143 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.9033 - mae: 0.1245\n",
            "Epoch 5: val_accuracy did not improve from 0.81530\n",
            "143/143 [==============================] - 158s 1s/step - loss: 0.2851 - accuracy: 0.9033 - mae: 0.1245 - val_loss: 0.9308 - val_accuracy: 0.5541 - val_mae: 0.4724\n",
            "Epoch 6/50\n",
            "143/143 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9314 - mae: 0.0795\n",
            "Epoch 6: val_accuracy did not improve from 0.81530\n",
            "143/143 [==============================] - 159s 1s/step - loss: 0.1808 - accuracy: 0.9314 - mae: 0.0795 - val_loss: 2.0705 - val_accuracy: 0.3931 - val_mae: 0.6141\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "C4Z1nxQLoSYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_best = tf.keras.models.load_model('/content/model.h5', custom_objects={'KerasLayer': bert_layer})"
      ],
      "metadata": {
        "id": "c772tOryCnq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_best.predict(test_input)\n",
        "# y_pred = model.predict(test_input)"
      ],
      "metadata": {
        "id": "YTPpWVgPSQb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_ = [np.argmax(i) for i in y_test]\n",
        "y_pred_ = [np.argmax(i) for i in y_pred]"
      ],
      "metadata": {
        "id": "UjEu6akP2eUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in1 = y_pred_\n",
        "true_classes = y_test_\n",
        "class_labels = [str(i) for i in range(2)]\n",
        "predicted_classes = (in1)\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)\n",
        "cm1 = confusion_matrix(true_classes,predicted_classes)\n",
        "#print(cm2)\n",
        "#Visualizing confusion matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=cm1, colorbar=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "a8A0e9fD3GAD",
        "outputId": "c56d7178-38a1-4799-989e-b604ec5188c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.58      0.66       186\n",
            "           1       0.68      0.84      0.75       193\n",
            "\n",
            "    accuracy                           0.71       379\n",
            "   macro avg       0.73      0.71      0.71       379\n",
            "weighted avg       0.73      0.71      0.71       379\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7UUUdAO_RssL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}